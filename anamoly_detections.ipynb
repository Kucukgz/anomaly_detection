{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.restoration import estimate_sigma\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy.ndimage import laplace\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.cluster import KMeans\n",
    "from pyoptflow import HornSchunck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_measurements(folder):\n",
    "    # list image files\n",
    "    filenames = os.listdir(folder)\n",
    "    # sort the image filenames\n",
    "    filenames = sorted(filenames, key=lambda v: v.upper())\n",
    "    nl, bs, bs2, ai, dl, di, cl, mz = [], [], [], [], [], [], [], []\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "        filename = os.path.join(folder, filename)\n",
    "        im = imread(filename)\n",
    "        im = np.moveaxis(im, 0, -1)\n",
    "        for i in range(im.shape[2]):\n",
    "            nl.append(estimate_sigma(im[:, :, i], multichannel=False, average_sigmas=True))\n",
    "            imlap = laplace(im[:, :, i])\n",
    "            bs.append(imlap.var())  # Blurriness Score\n",
    "            im2 = gaussian_filter(im[:, :, i], sigma=3)\n",
    "            bs2.append(im2.var())  # Blurriness Score with Gaussian Filter\n",
    "            ai.append(im[:, :, i].mean())  # Average Intensity\n",
    "            dl.append(_get_dark_light(im[:, :, i]))  # Darkness Level\n",
    "            di.append(_get_dominant_intensity(im[:, :, i]))  # Dominant intensity\n",
    "            imgx, imgy = np.gradient(im[:, :, i])\n",
    "            img = np.sqrt(np.power(imgx, 2) + np.power(imgy, 2))\n",
    "            cl.append(np.sum(img) / (im.shape[0] * im.shape[1]))  # Contrast Level\n",
    "        for i in range(im.shape[2] - 1):\n",
    "            _, _, m, _ = _motion_estimation(im[:, :, i], im[:, :, i + 1])\n",
    "            ali = np.sum(m)\n",
    "            mz.append(ali)  # Motion Estimation\n",
    "    return nl, bs, bs2, ai, dl, di, cl, mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _motion_estimation(im1, im2, a=1.0, n=100):\n",
    "    u, v = HornSchunck(im1, im2, alpha=a, Niter=n)\n",
    "    m = np.sqrt(np.power(u, 2) + np.power(v, 2))  # magnitude\n",
    "    a = np.arctan2(u, v)  # angle\n",
    "    return m, v, u, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dark_light(im):\n",
    "    # im - grayscale [0-255]\n",
    "    # intensity palette of the image\n",
    "    palette = defaultdict(int)\n",
    "    for pixel in np.nditer(im):\n",
    "        palette[int(pixel)] += 1\n",
    "    # sort the intensity present in the image\n",
    "    sorted_x = sorted(palette.items(), key=itemgetter(1), reverse=True)\n",
    "    light_shade, dark_shade, shade_count, pixel_limit = 0, 0, 0, 25\n",
    "    for _, x in enumerate(sorted_x[:pixel_limit]):\n",
    "        if x[0] <= 20:  # dull : too much darkness\n",
    "            dark_shade += x[1]\n",
    "        if x[0] >= 240:  # bright : too much whiteness\n",
    "            light_shade += x[1]\n",
    "        shade_count += x[1]\n",
    "    light_percent = round((float(light_shade) / shade_count) * 100, 2)\n",
    "    dark_percent = round((float(dark_shade) / shade_count) * 100, 2)\n",
    "    return dark_percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dominant_intensity(im):\n",
    "    # k-means\n",
    "    kmeans_cluster = KMeans(n_clusters=5)\n",
    "    kmeans_cluster.fit(im)\n",
    "    cluster_centers = kmeans_cluster.cluster_centers_\n",
    "    cluster_labels = kmeans_cluster.labels_\n",
    "    # dominant intensity\n",
    "    palette = np.uint8(cluster_centers)\n",
    "    dominant_intensity = palette[np.argmax(\n",
    "                          np.unique(cluster_labels, return_counts=True)[1])]\n",
    "    # from vector [1,...,z] - > 1 number\n",
    "    dominant_intensity = np.median(dominant_intensity)\n",
    "    return dominant_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure(x):\n",
    "    \"\"\"To figure all features.\"\"\"\n",
    "    for i, j in x:\n",
    "        plt.figure()\n",
    "        plt.scatter(range(len(i)), np.sort(i))\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel(f'{j}')\n",
    "        plt.title(f\"{j} Distribution\")\n",
    "        sns.despine()\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "        sns.distplot(i)\n",
    "        plt.title(f\"Distribution of {j}\")\n",
    "        sns.despine()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def anomaly_score(x):\n",
    "    \"\"\"To figure out anomaly scores.\"\"\"\n",
    "    # must calibrate it for all measurements\n",
    "    for i, j in x:\n",
    "        pd_i = pd.DataFrame(i)\n",
    "        isolation_forest = IsolationForest(n_estimators=100)\n",
    "        isolation_forest.fit(pd_i.values.reshape(-1, 1))\n",
    "        xx = np.linspace(pd_i.min(), pd_i.max(), len(pd_i)).reshape(-1, 1)\n",
    "        anomaly_score = isolation_forest.decision_function(xx)\n",
    "        outlier = isolation_forest.predict(xx)\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(xx, anomaly_score, label='anomaly score')\n",
    "        plt.fill_between(xx.T[0], np.min(anomaly_score), np.max(anomaly_score),\n",
    "                         where=outlier == -1, color='r',\n",
    "                         alpha=.4, label='Outlier Region')\n",
    "        plt.legend()\n",
    "        plt.ylabel(f'Anomaly Score')\n",
    "        plt.xlabel(f'{j}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def skew_kurt(x):\n",
    "    \"\"\"To figure out distribution.\"\"\"\n",
    "    for i, j in x:\n",
    "        pd_x = pd.DataFrame(i)\n",
    "        print(f\"Skewness of {j}: %f\" % pd_x.skew())\n",
    "        print(f\"Kurtosis of {j}: %f\" % pd_x.kurt())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # load images\n",
    "    folder = '/home/burak/vsc/first_part/all'\n",
    "    nl, bs, bs2, ai, dl, di, cl, mz = _get_measurements(folder)\n",
    "    values = ((nl, 'Noise Level'), (bs, 'Blurriness Score'), (bs2, 'Blurriness Score with Gaussian Filter'),\n",
    "              (ai, 'Average Intensity'), (dl, 'Darkness Level'), (di, 'Dominant Intensity'), (cl, 'Contrast Level'),\n",
    "              (mz, 'Motion Estimation'))\n",
    "    skew_kurt(values)\n",
    "    figure(values)\n",
    "    anomaly_score(values)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bitb1003144471e4b308bb505b884110c36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
